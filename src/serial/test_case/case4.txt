site reliability engineering site reliability engineering foreword google s story story scaling one great success stories computing industry marking shift towards itcentric business google one first companies define businessit alignment meant practice went inform concept devops wider community book written broad crosssection people made transition reality google grew time traditional role system administrator transformed questioned system administration say ca nt afford hold tradition authority think anew nt time wait everyone else catch introduction principles network system administration bur claimed system administration form humancomputer engineering strongly rejected reviewers said yet stage call engineering time felt field become lost trapped wizard culture could see way forward google drew line silicon forcing fate revised role called sre site reliability engineer friends among first new generation engineer formalized using software automation initially fiercely secretive happened inside outside google different google s experience unique time information methods flowed directions book shows willingness let sre thinking come shadows see google built legendary infrastructure also studied learned changed mind tools technologies along way face daunting challenges open spirit tribal nature culture often entrenches practitioners dogmatic positions hold industry back google overcame inertia book collection essays one company single common vision fact contributions aligned around single company s goal makes special common themes common characters software systems reappear several chapters see choices different perspectives know correlate resolve competing interests articles rigorous academic pieces personal accounts written pride variety personal styles perspective individual skill sets written bravely intellectual honesty refreshing uncommon industry literature claim never always others philosophical tentative reflecting variety personalities within culture plays role story turn read humility observers part journey information myriad conflicting challenges many questions real legacy volume nt x d done look back years come comparing ideas reasoning measure thoughts experiences impressive thing book existence today hear brazen culture show code culture ask questions grown around open source community rather expertise championed google company dared think problems first principles employ top talent high proportion phds tools components processes working alongside chains software people data nothing tells us solve problems universally point stories like far valuable code designs resulted implementations ephemeral documented reasoning priceless rarely access kind insight story one company fact many overlapping stories shows us scaling far photographic enlargement textbook computer architecture scaling business process rather machinery lesson alone worth weight electronic paper engage much selfcritical review world much reinvention repetition many years usenix lisa conference community discussing infrastructure plus conferences operating systems different today yet book still feels like rare offering detailed documentation google step watershed epoch tale copyingthough perhaps emulating inspire next step us unique intellectual honesty pages expressing leadership humility stories hopes fears successes failures salute courage authors editors allowing candor party handson experiences also benefit lessons learned inside cocoon mark burgess preface software engineering common children labor birth painful difficult labor birth actually spend effort yet software engineering discipline spends much time talking first period opposed second despite estimates total costs system incurred birth popular industry model conceives deployed operational software stabilized production therefore needing much less attention software engineers wrong lens see software engineering tends focus designing building software systems must another discipline focuses whole lifecycle software objects inception deployment operation refinement eventual peaceful decommissioning discipline usesand needs use a wide range skills separate concerns kinds engineers today answer discipline google calls site reliability engineering exactly site reliability engineering sre admit particularly clear name dopretty much every site reliability engineer google gets asked exactly actually regular basis unpacking term little first foremost sres engineers apply principles computer science engineering design development computing systems generally large distributed ones sometimes task writing software systems alongside product development counterparts sometimes task building additional pieces systems need like backups load balancing ideally reused across systems sometimes task figuring apply existing solutions new problems next focus system reliability ben treynor sloss google vp operations originator term sre claims reliability fundamental feature product system useful nobody use reliability critical sres focused finding ways improve design operation systems make scalable reliable efficient however expend effort direction point systems reliable enough instead invest efforts adding features building new products finally sres focused operating services built atop distributed computing systems whether services planetscale storage email hundreds millions users google began web search site name originally referred sre role keeping googlecom website running though run many services many websitesfrom internal infrastructure bigtable products external developers google cloud platform although represented sre broad discipline surprise arose fastmoving world web services perhaps origin owes something peculiarities infrastructure equally surprise postdeployment characteristics software could choose devote special attention reliability one regard primary domain web services process improving changing serverside software comparatively contained managing change tightly coupled failures kinds natural platform approach might emerge despite arising google web community generally think discipline lessons applicable communities organizations book attempt explain things organizations might make use learned better define role term means end organized book general principles specific practices separated possible appropriate discuss particular topic googlespecific information trust reader indulge us afraid draw useful conclusions environment also provided orienting materiala description google production environment mapping internal software publicly available softwarewhich help contextualize saying make directly usable ultimately course reliabilityoriented software systems engineering inherently good however acknowledge smaller organizations may wondering best use experience represented much like security earlier care reliability better implies even though small organization many pressing concerns software choices make may differ google made still worth putting lightweight reliability support place early less costly expand structure later introduce one present management contains number best practices training communication meetings found work well us many immediately usable organization sizes startup multinational probably already someone organization sre work without necessarily called name recognized another way get started path improving reliability organization formally recognize work find people foster doreward people stand cusp one way looking world another one like newton sometimes called world first physicist world last alchemist taking historical view looking back might first sre like think margaret hamilton working apollo program loan mit significant traits first sre words part culture learn everyone everything including one would least expect case point young daughter lauren came work one day team running mission scenarios hybrid simulation computer young children lauren went exploring caused mission crash selecting dsky keys unexpected way alerting team would happen prelaunch program p inadvertently selected real astronaut real mission real midcourse launching p inadvertently real mission would major problem wipes navigation data computer equipped pilot craft navigation data sre instincts margaret submitted program change request add special error checking code onboard flight software case astronaut accident happen select p flight move considered unnecessary higherups nasa course could never happen instead adding error checking code margaret updated mission specifications documentation say equivalent select p flight apparently update amusing many project told many times astronauts would make mistakesafter trained perfect well margaret suggested safeguard considered unnecessary next mission apollo days specifications update midcourse fourth day flight astronauts jim lovell william anders frank borman board jim lovell selected p mistakeas happens christmas daycreating much havoc involved critical problem absence workaround navigation data meant astronauts never coming home thankfully documentation update explicitly called possibility invaluable figuring upload usable data recover mission much time spare margaret says thorough understanding operate systems enough prevent human errors change request add error detection recovery software prelaunch program p approved shortly afterwards although apollo incident occurred decades ago much preceding paragraphs directly relevant engineers lives today much continue directly relevant future accordingly systems look groups work organizations building please bear sre way mind thoroughness dedication belief value preparation documentation awareness could go wrong coupled strong desire prevent welcome emerging profession read book book series essays written members alumni google site reliability engineering organization much like conference proceedings like standard book author small number authors chapter intended read part coherent whole good deal gained reading whatever subject particularly interests articles support inform text reference follow accordingly need read particular order though suggest least starting chapters production environment google viewpoint sre embracing risk describe google production environment outline sre approaches risk respectively risk many ways key quality profession reading covertocover course also useful possible chapters grouped thematically principles principles practices practices management management small introduction highlights individual pieces references articles published google sres covering specific topics detail additionally companion website book https gcosrebook number helpful resources hope least useful interesting putting together us editors conventions used book following typographical conventions used book italic indicates new terms urls email addresses filenames file extensions constant width used program listings well within paragraphs refer program elements variable function names databases data types environment variables statements keywords constant width bold shows commands text typed literally user constant width italic shows text replaced usersupplied values values determined context tip element signifies tip suggestion note element signifies general note warning element indicates warning caution using code examples supplemental material available https gcosrebook book help get job done general example code offered book may use programs documentation need contact us permission unless reproducing significant portion code example writing program uses several chunks code book require permission selling distributing cdrom examples reilly books require permission answering question citing book quoting example code require permission incorporating significant amount example code book product documentation require permission appreciate require attribution attribution usually includes title author publisher isbn example site reliability engineering edited betsy beyer chris jones jennifer petoff niall richard murphy reilly copyright google inc feel use code examples falls outside fair use permission given feel free contact us permissions oreillycom safari books online note safari books online ondemand digital library delivers expert content book video form world leading authors technology business technology professionals software developers web designers business creative professionals use safari books online primary resource research problem solving learning certification training safari books online offers range plans pricing enterprise government education individuals members access thousands books training videos prepublication manuscripts one fully searchable database publishers like reilly media prentice hall professional addisonwesley professional microsoft press sams que peachpit press focal press cisco press john wiley sons syngress morgan kaufmann ibm redbooks packt adobe press ft press apress manning new riders mcgrawhill jones bartlett course technology hundreds information safari books online please visit us online contact us please address comments questions concerning book publisher reilly media inc gravenstein highway north sebastopol ca united states canada international local fax web page book list errata examples additional information access page http bitlysitereliabilityengineering comment ask technical questions book send email bookquestions oreillycom information books courses conferences news see website http wwworeillycom find us facebook http facebookcomoreilly follow us twitter http twittercomoreillymedia watch us youtube http wwwyoutubecomoreillymedia acknowledgments book would possible without tireless efforts authors technical writers also like thank following internal reviewers providing especially valuable feedback alex matey dermot duffy jc van winkel john t reese michael reilly steve carstensen todd underwood ben lutch ben treynor sloss book sponsors within google belief project sharing learned running largescale services essential making book happen like send special thanks rik farrow editor login partnering us number contributions prepublication via usenix authors specifically acknowledged chapter like take time recognize contributed chapter providing thoughtful input discussion review embracing risk abe rahey ben treynor sloss brian stoler dave connor david besbris jill alvidrez mike curtis nancy chang tammy capistrant tom limoncelli eliminating toil cody smith george sadlier laurence berland marc alvidrez patrick stahlberg peter duff pim van pelt ryan anderson sabrina farmer seth hettich monitoring distributed systems mike curtis jamie wilkinson seth hettich release engineering david schnur jt goldstone marc alvidrez marcus larareinhold noah maxwell peter dinges sumitran raghunathan yutong cho simplicity ryan anderson practical alerting timeseries data jules anderson max luebbe mikel mcdaniel raul vera seth hettich oncall andrew stribblehill richard woodbury effective troubleshooting charles stephen gunn john hedditch peter nuttall rob ewaschuk sam greenfield emergency response jelena oertel kripa krishnan sergio salvi tim craig managing incidents amy zhou carla geisser grainne sheerin hildo biersma jelena oertel perry lorier rune kristian viken postmortem culture learning failure dan wu heather sherman jared brick mike louer štěpán davidovič tim craig tracking outages andrew stribblehill richard woodbury testing reliability isaac clerencia marc alvidrez software engineering sre ulric longyear load balancing frontend debashish chatterjee perry lorier chapters load balancing datacenter handling overload adam fletcher christoph pfisterer lukáš ježek manjot pahwa micha riser noah fiedel pavel herrmann paweł zuzelski perry lorier ralf wildenhues tudorioan salomie witold baryluk addressing cascading failures mike curtis ryan anderson managing critical state distributed consensus reliability ananth shrinivas mike burrows distributed periodic scheduling cron ben fried derek jackson gabe krabbe laura nolan seth hettich data processing pipelines abdulrahman salem alex perry arnar mar hrafnkelsson dieter pearcey dylan curley eivind eklund eric veach graham poulter ingvar mattsson john looney ken grant michelle duffy mike hochberg robinson data integrity read wrote corey vickrey dan ardelean disney luangsisongkham gordon prioreschi kristina bennett liang lin michael kelly sergey ivanyuk reliable product launches scale vivek rau accelerating sres oncall beyond melissa binde perry lorier preston yoshioka dealing interrupts ben lutch carla geisser dzevad trumic john turek matt brown embedding sre recover operational overload charles stephen gunn chris heiser max luebbe sam greenfield communication collaboration sre alex kehlenbeck jeromy carriere joel becker sowmya vijayaraghavan trevor mattsonhamilton evolving sre engagement model seth hettich lessons learned industries adrian hilton brad kratochvil charles ballowe dan sheridan eddie kennedy erik gross gus hartmann jackson stone jeff stevenson john li kevin greer matt toia michael haynie mike doherty peter dahl ron heiby also grateful following contributors either provided significant material excellent job reviewing agreed interviewed supplied significant expertise resources otherwise excellent effect work abe hassan adam rogoyski alex hidalgo amaya booker andrew fikes andrew hurst ariel goh ashleigh rentz ayman hourieh barclay osborn ben appleton ben love ben winslow bernhard beck bill duane bill patry blair zajac bob gruber brian gustafson bruce murphy buck clay cedric cellier chiho saito chris carlon christopher hahn chris kennelly chris taylor ciara kamahelesanfratello colin phipps colm buckley craig paterson daniel eisenbud daniel v klein daniel spoonhower dan watson dave phillips david hixson dina betser doron meyer dmitry fedoruk eric grosse eric schrock filip zyzniewski francis tang gary arneson georgina wilcox gretta bartels gustavo franco harald wagener healfdene goguen hugo santos hyrum wright ian gulliver jakub turski james chivers james kane james youngman jan monsch jason parkerburlingham jason petsod jeffry mcneil jeff dean jeff peck jennifer mace jerry cen jess frame john brady john gunderman john kochmar john tobin jordyn buchanan joseph bironas julio merino julius plenz kate ward kathy polizzi katrina sostek kenn hamm kirk russell kripa krishnan larry greenfield lea oliveira luca cittadini lucas pereira magnus ringman mahesh palekar marco paganini mario bonilla mathew mills mathew monroe matt d brown matt proud max saltonstall michal jaszczyk mihai bivol misha brukman olivier oansaldi patrick bernier pierre palatin rob shanley robert van gent rory ward rui zhangshen salim virji sanjay ghemawat sarah coty sean dorward sean quinlan sean sechrist shari trumbomchenry shawn morrissey shuntak leung stan jedrus stefano lattarini steven schirripa tanya reilly terry bolt tim chaplin toby weingartner tom black udi meiri victor terron vlad grama wes hertlein zoltan egyed much appreciate thoughtful indepth feedback received external reviewers andrew fong björn rabenstein charles border david blankedelman frossie economou james meickle josh ryder mark burgess russ allbery would like extend special thanks cian synnott original book team member coconspirator left google project completed deeply influential margaret hamilton graciously allowed us reference story preface additionally would like extend special thanks shylaja nukala generously gave time technical writers supported necessary valued efforts wholeheartedly editors would also like personally thank following people betsy beyer grandmother personal hero supplying endless amounts phone pep talks popcorn riba supplying sweatpants necessary fuel several late nights course addition cast sre allstars indeed delightful collaborators chris jones michelle saving life crime high seas uncanny ability find manzanas unexpected places taught engineering years jennifer petoff husband scott incredibly supportive two year process writing book keeping editors supplied plenty sugar dessert island niall murphy léan oisín fiachra considerably patient right expect substantially rantier father husband usual years dermot transfer offer the fact large variance estimates tells something software engineering discipline see eg gla details for purposes reliability probability system perform required function without failure stated conditions stated period time following definition oco the software systems concerned largely websites similar services discuss reliability concerns face software intended nuclear power plants aircraft medical equipment safetycritical systems however compare approaches used industries lessons learned industries in distinct industry term devops although definitely regard infrastructure code reliability main focus additionally strongly oriented toward removing necessity operationssee evolution automation google details in addition great story also substantial claim popularizing term software engineering part introduction section provides highlevel guidance sre different conventional industry practices ben treynor sloss senior vp overseeing technical operations google originator term site reliability engineering provides view sre means works compares ways things industry introduction provide guide production environment google production environment google viewpoint sre way help acquaint wealth new terms systems meet rest book chapter introduction written benjamin treynor sloss edited betsy beyer hope strategy traditional sre saying truth universally acknowledged systems run systemparticularly complex computing system operates large scalebe run sysadmin approach service management historically companies employed systems administrators run complex computing systems systems administrator sysadmin approach involves assembling existing software components deploying work together produce service sysadmins tasked running service responding events updates occur system grows complexity traffic volume generating corresponding increase events updates sysadmin team grows absorb additional work sysadmin role requires markedly different skill set required product developers developers sysadmins divided discrete teams development operations ops sysadmin model service management several advantages companies deciding run staff service approach relatively easy implement familiar industry paradigm many examples learn emulate relevant talent pool already widely available array existing tools software components shelf otherwise integration companies available help run assembled systems novice sysadmin team reinvent wheel design system scratch sysadmin approach accompanying developmentops split number disadvantages pitfalls fall broadly two categories direct costs indirect costs direct costs neither subtle ambiguous running service team relies manual intervention change management event handling becomes expensive service andor traffic service grows size team necessarily scales load generated system indirect costs developmentops split subtle often expensive organization direct costs costs arise fact two teams quite different background skill set incentives use different vocabulary describe situations carry different assumptions risk possibilities technical solutions different assumptions target level product stability split groups easily become one incentives also communication goals eventually trust respect outcome pathology traditional operations teams counterparts product development thus often end conflict visibly quickly software released production core development teams want launch new features see adopted users core ops teams want make sure service break holding pager outages caused kind changea new configuration new feature launch new type user trafficthe two teams goals fundamentally tension groups understand unacceptable state interests baldest possible terms want launch anything time without hindrance versus want ever change anything system works vocabulary risk assumptions differ groups often resort familiar form trench warfare advance interests ops team attempts safeguard running system risk change introducing launch change gates example launch reviews may contain explicit check every problem ever caused outage past could arbitrarily long list elements providing equal value dev team quickly learns respond fewer launches flag flips incremental updates cherrypicks adopt tactics sharding product fewer features subject launch review google approach service management site reliability engineering conflict inevitable part offering software service google chosen run systems different approach site reliability engineering teams focus hiring software engineers run products create systems accomplish work would otherwise performed often manually sysadmins exactly site reliability engineering come defined google explanation simple sre happens ask software engineer design operations team joined google tasked running production team seven engineers entire life point software engineering designed managed group way would want work worked sre group since matured become google presentday sre team remains true origins envisioned lifelong software engineer primary building block google approach service management composition sre team whole sres broken two main categories google software engineers precisely people hired via standard procedure google software engineers candidates close google software engineering qualifications ie skill set required addition set technical skills useful sre rare software engineers far unix system internals networking layer layer expertise two common types alternate technical skills seek common sres belief aptitude developing software systems solve complex problems within sre track career progress groups closely date found practical difference performance engineers two tracks fact somewhat diverse background sre team frequently results clever highquality systems clearly product synthesis several skill sets result approach hiring sre end team people quickly become bored performing tasks hand b skill set necessary write software replace previously manual work even solution complicated sres also end sharing academic intellectual background rest development organization therefore sre fundamentally work historically done operations team using engineers software expertise banking fact engineers inherently predisposed ability design implement automation software replace human labor design crucial sre teams focused engineering without constant engineering operations load increases teams need people keep pace workload eventually traditional opsfocused group scales linearly service size products supported service succeed operational load grow traffic means hiring people tasks avoid fate team tasked managing service needs code drown therefore google places cap aggregate ops work srestickets oncall manual tasks etc cap ensures sre team enough time schedule make service stable operable cap upper bound time left devices sre team end little operational load almost entirely engage development tasks service basically runs repairs want systems automatic automated practice scale new features keep sres toes google rule thumb sre team must spend remaining time actually development enforce threshold first place measure sre time spent measurement hand ensure teams consistently spending less time development work change practices often means shifting operations burden back development team adding staff team without assigning team additional operational responsibilities consciously maintaining balance ops development work allows us ensure sres bandwidth engage creative autonomous engineering still retaining wisdom gleaned operations side running service found google sre approach running largescale systems many advantages sres directly modifying code pursuit making google systems run sre teams characterized rapid innovation large acceptance change teams relatively inexpensivesupporting service opsoriented team would require significantly larger number people instead number sres needed run maintain improve system scales sublinearly size system finally sre circumvent dysfunctionality devops split structure also improves product development teams easy transfers product development sre teams crosstrain entire group improve skills developers otherwise may difficulty learning build millioncore distributed system despite net gains sre model characterized distinct set challenges one continual challenge google faces hiring sres sre compete candidates product development hiring pipeline fact set hiring bar high terms coding system engineering skills means hiring pool necessarily small discipline relatively new unique much industry information exists build manage sre team although hopefully book make strides direction sre team place potentially unorthodox approaches service management require strong management support example decision stop releases remainder quarter error budget depleted might embraced product development team unless mandated management devops sre term devops emerged industry late writing early still state flux core principlesinvolvement function phase system design development heavy reliance automation versus human effort application engineering practices tools operations tasksare consistent many sre principles practices one could view devops generalization several core sre principles wider range organizations management structures personnel one could equivalently view sre specific implementation devops idiosyncratic extensions tenets sre tenets sre nuances workflows priorities daytoday operations vary sre team sre team share set basic responsibilities service support adhere core tenets general sre team responsible availability latency performance efficiency change management monitoring emergency response capacity planning service codified rules engagement principles sre teams interact environmentnot production environment also product development teams testing teams users rules work practices help us maintain focus engineering work opposed operations work following section discusses core tenets google sre ensuring durable focus engineering already discussed google caps operational work sres time remaining time spent using coding skills project work practice accomplished monitoring amount operational work done sres redirecting excess operational work product development teams reassigning bugs tickets development managers integrating developers oncall pager rotations redirection ends operational load drops back lower also provides effective feedback mechanism guiding developers build systems need manual intervention approach works well entire organizationsre development alikeunderstands safety valve mechanism exists supports goal overflow events product generate enough operational load require focused operations work average sres receive maximum two events per hour oncall shift target volume gives oncall engineer enough time handle event accurately quickly clean restore normal service conduct postmortem two events occur regularly per oncall shift problems investigated thoroughly engineers sufficiently overwhelmed prevent learning events scenario pager fatigue also improve scale conversely oncall sres consistently receive fewer one event per shift keeping point waste time postmortems written significant incidents regardless whether paged postmortems trigger page even valuable likely point clear monitoring gaps investigation establish happened detail find root causes event assign actions correct problem improve addressed next time google operates blamefree postmortem culture goal exposing faults applying engineering fix faults rather avoiding minimizing pursuing maximum change velocity without violating service slo product development sre teams enjoy productive working relationship eliminating structural conflict respective goals structural conflict pace innovation product stability described earlier conflict often expressed indirectly sre bring conflict fore resolve introduction error budget error budget stems observation wrong reliability target basically everything pacemakers antilock brakes notable exceptions general software service system right reliability target user tell difference system available available many systems path user service laptop home wifi isp power grid systems collectively far less available thus marginal difference gets lost noise unavailability user receives benefit enormous effort required add last availability wrong reliability target system right reliability target system actually technical question all product question take following considerations account level availability users happy given use product alternatives available users dissatisfied product availability happens users usage product different availability levels business product must establish system availability target target established error budget one minus availability target service available unavailable permitted unavailability service error budget spend budget anything want long overspend want spend error budget development team wants launch features attract new users ideally would spend error budget taking risks things launch order launch quickly basic premise describes whole model error budgets soon sre activities conceptualized framework freeing error budget tactics phased rollouts experiments optimize quicker launches use error budget resolves structural conflict incentives development sre sre goal longer zero outages rather sres product developers aim spend error budget getting maximum feature velocity change makes difference outage longer bad thingit expected part process innovation occurrence development sre teams manage rather fear monitoring monitoring one primary means service owners keep track system health availability monitoring strategy constructed thoughtfully classic common approach monitoring watch specific value condition trigger email alert value exceeded condition occurs however type email alerting effective solution system requires human read email decide whether type action needs taken response fundamentally flawed monitoring never require human interpret part alerting domain instead software interpreting humans notified need take action three kinds valid monitoring output alerts signify human needs take action immediately response something either happening happen order improve situation tickets signify human needs take action immediately system automatically handle situation human takes action days damage result logging one needs look information recorded diagnostic forensic purposes expectation one reads logs unless something else prompts emergency response reliability function mean time failure mttf mean time repair mttr sch relevant metric evaluating effectiveness emergency response quickly response team bring system back healththat mttr humans add latency even given system experiences actual failures system avoid emergencies require human intervention higher availability system requires handson intervention humans necessary found thinking recording best practices ahead time playbook produces roughly x improvement mttr compared strategy winging hero jackofalltrades oncall engineer work practiced oncall engineer armed playbook works much better playbook matter comprehensive may substitute smart engineers able think fly clear thorough troubleshooting steps tips valuable responding highstakes timesensitive page thus google sre relies oncall playbooks addition exercises wheel misfortune prepare engineers react oncall events change management sre found roughly outages due changes live system best practices domain use automation accomplish following implementing progressive rollouts quickly accurately detecting problems rolling back changes safely problems arise trio practices effectively minimizes aggregate number users operations exposed bad changes removing humans loop practices avoid normal problems fatigue familiaritycontempt inattention highly repetitive tasks result release velocity safety increase demand forecasting capacity planning demand forecasting capacity planning viewed ensuring sufficient capacity redundancy serve projected future demand required availability nothing particularly special concepts except surprising number services teams take steps necessary ensure required capacity place time needed capacity planning take organic growth stems natural product adoption usage customers inorganic growth results events like feature launches marketing campaigns businessdriven changes account several steps mandatory capacity planning accurate organic demand forecast extends beyond lead time required acquiring capacity accurate incorporation inorganic demand sources demand forecast regular load testing system correlate raw capacity servers disks service capacity capacity critical availability naturally follows sre team must charge capacity planning means also must charge provisioning provisioning provisioning combines change management capacity planning experience provisioning must conducted quickly necessary capacity expensive exercise must also done correctly capacity work needed adding new capacity often involves spinning new instance location making significant modification existing systems configuration files load balancers networking validating new capacity performs delivers correct results thus riskier operation load shifting often done multiple times per hour must treated corresponding degree extra caution efficiency performance efficient use resources important time service cares money sre ultimately controls provisioning must also involved work utilization utilization function given service works provisioned follows paying close attention provisioning strategy service therefore utilization provides big lever service total costs resource use function demand load capacity software efficiency sres predict demand provision capacity modify software three factors large part though entirety service efficiency software systems become slower load added slowdown service equates loss capacity point slowing system stops serving corresponds infinite slowness sres provision meet capacity target specific response speed thus keenly interested service performance sres product developers monitor modify service improve performance thus adding capacity improving efficiency end beginning site reliability engineering represents significant break existing industry best practices managing large complicated services motivated originally familiarity software engineer would want invest time accomplish set repetitive tasks it become much set principles set practices set incentives field endeavor within larger software engineering discipline rest book explores sre way detail vice president google engineering founder google sre see disaster role playing for discussion collaboration work practice see communications production meetings chapter production environment google viewpoint sre written jc van winkeledited betsy beyer google datacenters different conventional datacenters smallscale server farms differences present extra problems opportunities chapter discusses challenges opportunities characterize google datacenters introduces terminology used throughout book hardware google compute resources googledesigned datacenters proprietary power distribution cooling networking compute hardware see bar unlike standard colocation datacenters compute hardware googledesigned datacenter across board eliminate confusion server hardware server software use following terminology throughout book machine piece hardware perhaps vm server piece software implements service machines run server dedicate specific machines specific server programs specific machine runs mail server example instead resource allocation handled cluster operating system borg realize use word server unusual common use word conflates binary accepts network connection machine differentiating two important talking computing google get used usage server becomes apparent makes sense use specialized terminology within google also rest book figure illustrates topology google datacenter tens machines placed rack racks stand row one rows form cluster usually datacenter building houses multiple clusters multiple datacenter buildings located close together form campus figure example google datacenter campus topology machines within given datacenter need able talk created fast virtual switch tens thousands ports accomplished connecting hundreds googlebuilt switches clos network fabric clos named jupiter sin largest configuration jupiter supports pbps bisection bandwidth among servers datacenters connected globespanning backbone network b jai b softwaredefined networking architecture uses openflow openstandard communications protocol supplies massive bandwidth modest number sites uses elastic bandwidth allocation maximize average bandwidth kum system software organizes hardware hardware must controlled administered software handle massive scale hardware failures one notable problem manage software given large number hardware components cluster hardware failures occur quite frequently single cluster typical year thousands machines fail thousands hard disks break multiplied number clusters operate globally numbers become somewhat breathtaking therefore want abstract problems away users teams running services similarly want bothered hardware failures datacenter campus teams dedicated maintaining hardware datacenter infrastructure managing machines borg illustrated figure distributed cluster operating system ver similar apache mesos borg manages jobs cluster level figure highlevel borg cluster architecture borg responsible running users jobs either indefinitely running servers batch processes like mapreduce dea jobs consist one sometimes thousands identical tasks reasons reliability single process usually handle cluster traffic borg starts job finds machines tasks tells machines start server program borg continually monitors tasks task malfunctions killed restarted possibly different machine tasks fluidly allocated machines simply rely ip addresses port numbers refer tasks solve problem extra level indirection starting job borg allocates name index number task using borg naming service bns rather using ip address port number processes connect borg tasks via bns name translated ip address port number bns example bns path might string bns cluster user job name task number would resolve ip address port borg also responsible allocation resources jobs every job needs specify required resources eg cpu cores gib ram using list requirements jobs borg binpack tasks machines optimal way also accounts failure domains example borg run job tasks rack means top rack switch single point failure job task tries use resources requested borg kills task restarts slowly crashlooping task usually preferable task restarted storage tasks use local disk machines scratch pad several cluster storage options permanent storage even scratch space eventually move cluster storage model comparable lustre hadoop distributed file system hdfs open source cluster filesystems storage layer responsible offering users easy reliable access storage available cluster shown figure storage many layers lowest layer called disk although uses spinning disks flash storage fileserver running almost machines cluster however users want access data want remember machine storing data next layer comes play layer top called colossus creates clusterwide filesystem offers usual filesystem semantics well replication encryption colossus successor gfs google file system ghe several databaselike services built top colossus bigtable cha nosql database system handle databases petabytes size bigtable sparse distributed persistent multidimensional sorted map indexed row key column key timestamp value map uninterpreted array bytes bigtable supports eventually consistent crossdatacenter replication spanner cor offers sqllike interface users require real consistency across world several database systems blobstore available options comes set tradeoffs see data integrity read wrote figure portions google storage stack networking google network hardware controlled several ways discussed earlier use openflowbased softwaredefined network instead using smart routing hardware rely less expensive dumb switching components combination central duplicated controller precomputes best paths across network therefore able move computeexpensive routing decisions away routers use simple switching hardware network bandwidth needs allocated wisely borg limits compute resources task use bandwidth enforcer bwe manages available bandwidth maximize average available bandwidth optimizing bandwidth cost centralized traffic engineering shown solve number problems traditionally extremely difficult solve combination distributed routing traffic engineering kum services jobs running multiple clusters distributed across world order minimize latency globally distributed services want direct users closest datacenter available capacity global software load balancer gslb performs load balancing three levels geographic load balancing dns requests example wwwgooglecom described load balancing frontend load balancing user service level example youtube google maps load balancing remote procedure call rpc level described load balancing datacenter service owners specify symbolic name service list bns addresses servers capacity available locations typically measured queries per second gslb directs traffic bns addresses system software several components datacenter also important lock service chubby bur lock service provides filesystemlike api maintaining locks chubby handles locks across datacenter locations uses paxos protocol asynchronous consensus see managing critical state distributed consensus reliability chubby also plays important role master election service five replicas job running reliability purposes one replica may perform actual work chubby used select replica may proceed data must consistent well suited storage chubby reason bns uses chubby store mapping bns paths ip address port pairs monitoring alerting want make sure services running required therefore run many instances borgmon monitoring program see practical alerting timeseries data borgmon regularly scrapes metrics monitored servers metrics used instantaneously alerting also stored use historic overviews eg graphs use monitoring several ways set alerting acute problems compare behavior software update make server faster examine resource consumption behavior evolves time essential capacity planning software infrastructure software architecture designed make efficient use hardware infrastructure code heavily multithreaded one task easily use many cores facilitate dashboards monitoring debugging every server http server provides diagnostics statistics given task google services communicate using remote procedure call rpc infrastructure named stubby open source version grpc available often rpc call made even call subroutine local program needs performed makes easier refactor call different server modularity needed server codebase grows gslb load balance rpcs way load balances externally visible services server receives rpc requests frontend sends rpcs backend traditional terms frontend called client backend called server data transferred rpc using protocol buffers often abbreviated protobufs similar apache thrift protocol buffers many advantages xml serializing structured data simpler use times smaller times faster less ambiguous development environment development velocity important google built complete development environment make use infrastructure morb apart groups open source repositories eg android chrome google software engineers work single shared repository pot important practical implications workflows engineers encounter problem component outside project fix problem send proposed changes changelist cl owner review submit cl mainline changes source code engineer project require review software reviewed submitted software built build request sent build servers datacenter even large builds executed quickly many build servers compile parallel infrastructure also used continuous testing time cl submitted tests run software may depend cl either directly indirectly framework determines change likely broke parts system notifies owner submitted change projects use pushongreen system new version automatically pushed production passing tests shakespeare sample service provide model service would hypothetically deployed google production environment let look example service interacts multiple google technologies suppose want offer service lets determine given word used throughout shakespeare works divide system two parts batch component reads shakespeare texts creates index writes index bigtable job need run perhaps infrequently never know new text might discovered application frontend handles enduser requests job always users time zones want search shakespeare books batch component mapreduce comprising three phases mapping phase reads shakespeare texts splits individual words faster performed parallel multiple workers shuffle phase sorts tuples word reduce phase tuple word list locations created tuple written row bigtable using word key life request figure shows user request serviced first user points browser shakespearegooglecom obtain corresponding ip address user device resolves address dns server request ultimately ends google dns server talks gslb gslb keeps track traffic load among frontend servers across regions picks server ip address send user figure life request browser connects http server ip server named google frontend gfe reverse proxy terminates tcp connection gfe looks service required web search maps orin caseshakespeare using gslb server finds available shakespeare frontend server sends server rpc containing http request shakespeare server analyzes http request constructs protobuf containing word look shakespeare frontend server needs contact shakespeare backend server frontend server contacts gslb obtain bns address suitable unloaded backend server shakespeare backend server contacts bigtable server obtain requested data answer written reply protobuf returned shakespeare backend server backend hands protobuf containing results shakespeare frontend server assembles html returns answer user entire chain events executed blink eyejust hundred milliseconds many moving parts involved many potential points failure particular failing gslb would wreak havoc however google policies rigorous testing careful rollout addition proactive error recovery methods graceful degradation allow us deliver reliable service users come expect people regularly use wwwgooglecom check internet connection set correctly job data organization load testing determined backend server handle queries per second qps trials performed limited set users lead us expect peak load qps need least tasks however following considerations mean need least tasks job n updates one task time unavailable leaving tasks machine failure might occur task update leaving tasks enough serve peak load closer examination user traffic shows peak usage distributed globally qps north america south america europe africa asia australia instead locating backends one site distribute across usa south america europe asia allowing n redundancy per region means end tasks usa europe asia however decide use tasks instead south america lower overhead n n case willing tolerate small risk higher latency exchange lower hardware costs gslb redirects traffic one continent another south american datacenter capacity save resources spend hardware larger regions spread tasks across two three clusters extra resiliency backends need contact bigtable holding data need also design storage element strategically backend asia contacting bigtable usa adds significant amount latency replicate bigtable region bigtable replication helps us two ways provides resilience bigtable server fail lowers dataaccess latency bigtable offers eventual consistency major problem need update contents often introduced lot terminology need remember useful framing many systems refer later well roughly mostly except stuff different datacenters end multiple generations compute hardware sometimes augment datacenters built part datacenter hardware homogeneous some readers may familiar borg descendant kubernetesan open source container cluster orchestration framework started google see http kubernetesio bur details similarities borg apache mesos see ver see http grpcio protocol buffers languageneutral platformneutral extensible mechanism serializing structured data details see https developersgooglecomprotocolbuffers we assume probability two simultaneous task failures environment low enough negligible single points failure topofrack switches power distribution may make assumption invalid environments part ii principles section examines principles underlying sre teams typically work the patterns behaviors areas concern influence general domain sre operations first chapter section important piece read want attain widestangle picture exactly sre reason embracing risk looks sre lens riskits assessment management use error budgets provide usefully neutral approaches service management service level objectives another foundational conceptual unit sre industry commonly lumps disparate concepts general banner service level agreements tendency makes harder think concepts clearly service level objectives attempts disentangle indicators objectives agreements examines sre uses terms provides recommendations find useful metrics applications eliminating toil one sre important tasks subject eliminating toil define toil mundane repetitive operational work providing enduring value scales linearly service growth whether google elsewhere monitoring absolutely essential component right thing production monitor service know happening blind happening reliable read monitoring distributed systems recommendations monitor implementationagnostic best practices evolution automation google examine sre approach automation walk case studies sre implemented automation successfully unsuccessfully companies treat release engineering afterthought however learn release engineering release engineering critical overall system stabilityas outages result pushing change kind also best way ensure releases consistent key principle effective software engineering reliabilityoriented engineering simplicity quality lost extraordinarily difficult recapture nevertheless old adage goes complex system works necessarily evolved simple system works simplicity goes topic detail reading google sre increasing product velocity safely core principle organization making push green reality kle published october show taking humans release process paradoxically reduce sres toil increasing system reliability chapter embracing risk written marc alvidrez edited kavita guliani might expect google try build reliable servicesones never fail turns past certain point however increasing reliability worse service users rather better extreme reliability comes cost maximizing stability limits fast new features developed quickly products delivered users dramatically increases cost turn reduces numbers features team afford offer users typically notice difference high reliability extreme reliability service user experience dominated less reliable components like cellular network device working put simply user reliable smartphone tell difference service reliability mind rather simply maximizing uptime site reliability engineering seeks balance risk unavailability goals rapid innovation efficient service operations users overall happinesswith features service performanceis optimized managing risk unreliable systems quickly erode users confidence want reduce chance system failure however experience shows build systems cost increase linearly reliability incrementsan incremental improvement reliability may cost x previous increment costliness two dimensions cost redundant machinecompute resources cost associated redundant equipment example allows us take systems offline routine unforeseen maintenance provides space us store parity code blocks provide minimum data durability guarantee opportunity cost cost borne organization allocates engineering resources build systems features diminish risk instead features directly visible usable end users engineers longer work new features products end users sre manage service reliability largely managing risk conceptualize risk continuum give equal importance figuring engineer greater reliability google systems identifying appropriate level tolerance services run allows us perform costbenefit analysis determine example nonlinear risk continuum place search ads gmail photos goal explicitly align risk taken given service risk business willing bear strive make service reliable enough reliable needs set availability target want exceed much would waste opportunities add features system clean technical debt reduce operational costs sense view availability target minimum maximum key advantage framing unlocks explicit thoughtful risktaking measuring service risk standard practice google often best served identifying objective metric represent property system want optimize setting target assess current performance track improvements degradations time service risk immediately clear reduce potential factors single metric service failures many potential effects including user dissatisfaction harm loss trust direct indirect revenue loss brand reputational impact undesirable press coverage clearly factors hard measure make problem tractable consistent across many types systems run focus unplanned downtime services straightforward way representing risk tolerance terms acceptable level unplanned downtime unplanned downtime captured desired level service availability usually expressed terms number nines would like provide availability additional nine corresponds order magnitude improvement toward availability serving systems metric traditionally calculated based proportion system uptime see timebased availability timebased availability using formula period year calculate acceptable number minutes downtime reach given number nines availability example system availability target minutes year stay within availability target see availability table table google however timebased metric availability usually meaningful looking across globally distributed services approach fault isolation makes likely serving least subset traffic given service somewhere world given time ie least partially times therefore instead using metrics around uptime define availability terms request success rate aggregate availability shows yieldbased metric calculated rolling window ie proportion successful requests oneday window aggregate availability example system serves m requests day daily availability target serve errors still hit target given day typical application requests equal failing new user signup request different failing request polling new email background many cases however availability calculated request success rate requests reasonable approximation unplanned downtime viewed enduser perspective quantifying unplanned downtime request success rate also makes availability metric amenable use systems typically serve end users directly nonserving systems eg batch pipeline storage transactional systems welldefined notion successful unsuccessful units work indeed systems discussed chapter primarily consumer infrastructure serving systems many principles also apply nonserving systems minimal modification example batch process extracts transforms inserts contents one customer databases data warehouse enable analysis may set run periodically using request success rate defined terms records successfully unsuccessfully processed calculate useful availability metric despite fact batch system run constantly often set quarterly availability targets service track performance targets weekly even daily basis strategy lets us manage service highlevel availability objective looking tracking fixing meaningful deviations inevitably arise see service level objectives details risk tolerance services mean identify risk tolerance service formal environment case safetycritical systems risk tolerance services typically built directly basic product service definition google services risk tolerance tends less clearly defined identify risk tolerance service sres must work product owners turn set business goals explicit objectives engineer case business goals concerned direct impact performance reliability service offered practice translation easier said done consumer services often clear product owners unusual infrastructure services eg storage systems generalpurpose http caching layer similar structure product ownership discuss consumer infrastructure cases turn identifying risk tolerance consumer services consumer services often product team acts business owner application example search google maps google docs product managers product managers charged understanding users business shaping product success marketplace product team exists team usually best resource discuss reliability requirements service absence dedicated product team engineers building system often play role either knowingly unknowingly many factors consider assessing risk tolerance services following level availability required different types failures different effects service use service cost help locate service risk continuum service metrics important take account target level availability target level availability given google service usually depends function provides service positioned marketplace following list includes issues consider level service users expect service tie directly revenue either revenue customers revenue paid service free competitors marketplace level service competitors provide service targeted consumers enterprises consider requirements google apps work majority users enterprise users large small enterprises depend google apps work services eg gmail calendar drive docs provide tools enable